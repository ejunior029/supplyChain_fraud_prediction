# Detec√ß√£o de Opera√ß√µes Fraudulentas - DataCo Global
<img src=https://i.ibb.co/FbkZDPw/fraude.png>

## üìå Descri√ß√£o do Projeto
Este reposit√≥rio √© o cora√ß√£o do projeto de analytics da DataCo Global, onde mergulhamos profundamente nos dados para desvendar as opera√ß√µes da empresa e otimizar seu desempenho. Nosso foco principal foi na detec√ß√£o de fraudes, visando salvar a empresa de perdas significativas e impulsionar sua efici√™ncia operacional.

üìÑ [Veja a apresenta√ß√£o do projeto](https://github.com/ejunior029/supplyChain_fraud_prediction/blob/master/reports/Apresenta%C3%A7%C3%A3o%20-%20%20DataCo%20Global.pdf)  
üìÑ [Veja o notebook do case fraude](https://github.com/ejunior029/supplyChain_fraud_prediction/blob/master/notebooks/Fraude_Supply_Chain.ipynb)

## üíº Entendimento do Neg√≥cio

Em um mundo onde transa√ß√µes financeiras se tornaram a grande moeda do com√©rcio global, a seguran√ßa e integridade desses processos s√£o de suma import√¢ncia. Empresas de supply chain que operam internacionalmente est√£o **cada vez mais vulner√°veis a esquemas fraudulentos**, que n√£o s√≥ comprometem suas finan√ßas mas tamb√©m sua credibilidade e opera√ß√µes. 

Ao adentrar a era do big data e aprendizado de m√°quina, temos a oportunidade de **criar barreiras mais sofisticadas e adaptativas contra a fraude**.

Este projeto desenvolve um **modelo avan√ßado de machine learning** com a capacidade de **detectar e prever atividades fraudulentas** em uma escala global. 
  
  
### **Principais KPIs (Indicadores Chave de Desempenho) de Fraude:**

- **Estrat√©gias de Aceita√ß√£o:** Melhoria da precis√£o na aceita√ß√£o de transa√ß√µes leg√≠timas, reduzindo o impacto dos falsos positivos.
- **Lucro Bruto:** Opera√ß√µes financeiras que eram fraude e que foram corretamente negadas
- **Perda Financeira**: Opera√ß√µes financeiras que eram fraude e que n√£o foram identificadas
- **Lucro L√≠quido**: Lucro remanescente das fraudes identificadas corretamente e das n√£o identificadas

## üõ† Pr√©-Processamento Dos Dados

### _Considera√ß√µes_
1. Foram consideradas as vendas realizadas somente at√© setembro/2017 devido a um poss√≠vel problema operacional na base, que fez com que ap√≥s esta data apenas vendas a novos clientes fossem consideradas, desconsiderando os clientes antigos. Al√©m disso, os clientes novos compravam apenas uma vez. Sendo assim, para n√£o trabalhar com um conjunto de dados com uma poss√≠vel interfer√™ncia, foi realizado este filtro.
2. As colunas a seguir:  
    * *Order Item Product Price*
    * *Sales*
    * *Order Item Total*
    * *Product Price*
    * *Order Profit Per Order*

Foram consideradas como **unidades financeiras** no modelo (ex: D√≥lar)

### _Foram removidas todas as vari√°veis n√£o entendidas como importantes para o modelo_

1. Vari√°veis do tipo *date*
   * *Days for shipping (real)*
   * *Days for shipment (scheduled)*
   * *shipping date (DateOrders)*
   * *order date (DateOrders)*
     
2. Vari√°veis contendo ID
   * *Customer Id*
   * *Order Customer Id*
   * *Order Id*
   * *Order Item Cardprod Id*
   * *Order Item Id*
   * *Product Card Id*

3. Informa√ß√µes pessoais de clientes
   * *Category Name*
   * *Customer Email*
   * *Customer Fname*
   * *Customer Lname*
   * *Customer Password*

4. Dados de Localiza√ß√£o
   * *Customer Street*
   * *Customer Zipcode*
   * *Latitude*
   * *Longitude*

5. Dados de Produtos
   * *Product Description*
   * *Product Image*
   * *Product Status*

6. Dados de Pedidos
   * *Order Profit Per Order*
   * *Delivery Status
   * *Order Status*

7. Demais colunas removidas
   * *Category Name*
   * *Department Name*
  
### _Foi criado um Pipeline para fazer o pr√©-processamento automaticamente no conjunto de testes, de tal forma que considerasse_:

**1. Tratamento de Vari√°veis Categ√≥ricas**
  * O tratamento de vari√°veis categ√≥ricas foi realizado com o CatBoostEncoder

**2. Tratamento de *Missing Values***
  * O preenchimento de valores faltantes para vari√°veis categ√≥ricas com a moda
  * O preenchimento de valores faltantes para vari√°veis num√©ricas com a mediana
 
## ü§ñ Modelagem

Os dados s√£o extremamente desbalanceados, conforme a Figura abaixo:

<img src="https://i.ibb.co/7zjpbkF/fraude.png">

Possuindo apenas 2,3% de opera√ß√µes fraudulentas. 

Sendo assim, foi constru√≠da uma fun√ß√£o de valida√ß√£o cruzada estratificada (devido ao desbalanceamento), dividindo os dados em 5 folds.

<img src=https://i.ibb.co/RPMwXQ5/vc.png>

Com isso, foram obtidas 5 valores para cada m√©trica, sendo realizada a m√©dia para chegar √† um √∫nico valor representativo.

Al√©m disso, neste projeto foram utilizados os seguintes modelos:

- LightGBM
- XGBoost
- CatBoost
- Balanced Random Forest

### **Feature Selection**

Como o XGBoost obteve o melhor desempenho geral, foi o modelo escolhido para passar por um processo de feature selection que envolve a sele√ß√£o das vari√°veis (atributos) mais importantes para serem usadas na constru√ß√£o do modelo preditivo. O objetivo √© **melhorar a performance** do modelo, **reduzir a complexidade computacional** e **evitar o overfitting**. Foi utilizada a t√©cnica chamada ***Recursive Feature Elimination*** (RFE), que √© uma abordagem que seleciona atributos por meio de um processo iterativo de ajuste do modelo e remo√ß√£o das vari√°veis menos importantes.

<img src=https://i.ibb.co/TMW4jx2/feature-selection.png>

Pela imagem acima, percebe-se que a vari√°vel **Type** √© disparada a que mais influencia nas previs√µes do modelo, com uma import√¢ncia de 85%. Ou seja, o tipo de pagamento √© um fator decisivo para a opera√ß√£o ser considerada fraudulenta. Foram exclu√≠das as 6 vari√°veis com menor resultado de import√¢ncia, no gr√°fico aparecem apenas as selecionadas.

### **SHAP Values**

O valor Shap √© uma medida de impacto de cada feature na previs√£o de cada uma das inst√¢ncias. Quanto maior o valor SHAP de uma caracter√≠stica, mais import√¢nte √© a feature. No gr√°fico a seguir, foram calculados os valores SHAP **do primeiro registro do conjunto de teste**. Os valores SHAP s√£o calculados **para cada observa√ß√£o separadamente**, mostrando a contribui√ß√£o de cada caracter√≠stica para a previs√£o do modelo.

<img src=https://i.ibb.co/NTtdgg7/SHAP-VALUE.png>

No gr√°fico acima:

* E(f(x)): √© a expectativa (ou m√©dia) dos valores de f(x) sobre o conjunto de dados de teste. Em outras palavras, √© o valor que o modelo prev√™ na aus√™ncia de toda features.

* f(x): √â o score bruto previsto para a observa√ß√£o espec√≠fica ap√≥s a influ√™ncia de todas as features

Cada barra no gr√°fico SHAP representa a contribui√ß√£o de uma feature para a pontua√ß√£o bruta (f(x)) daquela observa√ß√£o espec√≠fica. Valores positivos indicam que a caracter√≠stica aumentou a pontua√ß√£o bruta, tornando mais prov√°vel a classifica√ß√£o na classe positiva, enquanto valores negativos indicam que a caracter√≠stica diminuiu a pontua√ß√£o bruta, tornando menos prov√°vel a classifica√ß√£o na classe positiva. O resultado do gr√°fico mostra que, para a primeira observa√ß√£o, a caracter√≠stica que mais contribuiu foi a vari√°vel **Type**.

Para transformar o score bruto (que pode ser interpretado como log-odds) em uma probabilidade, usamos a fun√ß√£o sigmoid, assim como na regress√£o log√≠stica. A fun√ß√£o sigmoid √© definida como:

$$P(y=1) = \frac{1}{1+e^{-f(x)}}$$

Em que $P(y=1)$ √© a probabilidade prevista da observa√ß√£o relacionada √† classe positiva.

### **Tunagem de Hiperpar√¢metros**

Em seguida o XGBoost passou por um processo de tunagem de hiperpar√¢metros, atrav√©s de um algoritmo de otimiza√ß√£o bayesiana que teve o objetivo de encontrar os par√¢metros que maximizassem a m√©trica ROC AUC. Ao final do processo, o XGBoost apresentou os seguintes resultados:

- M√©dia da ROC_AUC: 0.9043
- M√©dia da Revoca√ß√£o: 0.9394
- M√©dia da Precis√£o: 0.1422
- M√©dia da Medida-F1: 0.2469
- M√©dia da Precision-Recall AUC: 0.5415
- M√©dia da Acur√°cia: 0.8708

Com isso, o XGBoost foi escolhido para identificar o quanto a DataCo Global poderia deixar de perder se possu√≠sse um modelo antifraude para fazer a seguran√ßa de opera√ß√µes financeiras de pagamento dos clientes.

## üí°Desempenho Financeiro e M√©tricas

No processo de extrair o m√°ximo do modelo para evitar perdas financeiras oriundas de opera√ß√µes fraudulentas, foram obtidos os seguintes resultados para m√©tricas e indicadores financeiros:

- **Threshold √ìtimo:** 86
- **Economia Significativa:** Implementa√ß√£o do modelo de detec√ß√£o de fraude resultaria em uma economia estimada de **$1.09 milh√£o**.
- **Desafios Identificados:** A an√°lise revelou uma perda potencial de aproximadamente **$22 mil** devido a opera√ß√µes fraudulentas n√£o detectadas.
- **Impacto L√≠quido:** Com as melhorias propostas, a economia total projetada √© de aproximadamente **$1.07 milh√£o**.
- **Raz√£o Lucro/Receita:** 97.99% 

## üöß Pr√≥ximos Passos
A fase subsequente do projeto √© o seu deployment, envolvendo a implanta√ß√£o do modelo em um ambiente operacional para avalia√ß√£o da sua efici√™ncia em condi√ß√µes reais.


